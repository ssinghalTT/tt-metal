// SPDX-FileCopyrightText: Â© 2024 Tenstorrent Inc.
//
// SPDX-License-Identifier: Apache-2.0

#pragma once

#include <pybind11/pybind11.h>
#include <pybind11/stl.h>

#include "cpp/pybind11/decorators.hpp"
#include "untilize_with_halo_v2.hpp"

namespace ttnn::operations::data_movement::detail {
namespace py = pybind11;

void bind_untilize_with_halo_v2(py::module& module) {
    auto doc =
        R"doc(

            Untilizes input tiled data to row major format and constructs halo'd output shards.

        Args:
            input_tensor (ttnn.Tensor): the input tensor.
            padding_config (ttnn.Tensor): Padding config tensor.
            local_config (ttnn.Tensor): Local config tensor.
            remote_config (ttnn.Tensor): Remote config tensor.

        Keyword Args:
            pad_val (int, optional): pad value.
            ncores_nhw (int, optional): Number of cores per NHW..
            max_out_nsticks_per_core (int, optional): Max output nsticks per core.
            memory_config (ttnn.MemoryConfig, optional): Memory configuration for the operation. Defaults to `None`.
            remote_read (bool, optional): Remote read.  Defaults to `False`.
            transpose_mcast (bool, optional): Transpose mcast.  Defaults to `False`.
            queue_id (int, optional): command queue id. Defaults to `0`.
        Returns:
            ttnn.Tensor: the output tensor.

        )doc";

    using OperationType = decltype(ttnn::untilize_with_halo_v2);
    ttnn::bind_registered_operation(
        module,
        ttnn::untilize_with_halo_v2,
        doc,
        ttnn::pybind_overload_t{
            [](const OperationType& self,
               const ttnn::Tensor& input_tensor,
               const ttnn::Tensor& padding_config,
               const ttnn::Tensor& local_config,
               const ttnn::Tensor& remote_config,
               const uint32_t pad_val,
               const uint32_t ncores_nhw,
               const uint32_t max_out_nsticks_per_core,
               const std::optional<MemoryConfig>& memory_config,
               const bool remote_read,
               const bool transpose_mcast,
               uint8_t queue_id) {
                return self(
                    queue_id,
                    input_tensor,
                    padding_config,
                    local_config,
                    remote_config,
                    pad_val,
                    ncores_nhw,
                    max_out_nsticks_per_core,
                    memory_config,
                    remote_read,
                    transpose_mcast);
            },
            py::arg("input_tensor"),
            py::arg("padding_config"),
            py::arg("local_config"),
            py::arg("remote_config"),
            py::kw_only(),
            py::arg("pad_val"),
            py::arg("ncores_nhw"),
            py::arg("max_out_nsticks_per_core"),
            py::arg("memory_config") = std::nullopt,
            py::arg("remote_read") = false,
            py::arg("transpose_mcast") = false,
            py::arg("queue_id") = 0,
        });
}
}  // namespace ttnn::operations::data_movement::detail
